<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Big Data,">





  <link rel="alternate" href="/atom.xml" title="ixyxj" type="application/atom+xml">






<meta name="description" content="概述大数据需要多台服务器集群, 如果用云服务器的话让很多新手都望之却步, 我们来配置穷逼本地虚拟机集群.这也为后面的hadoop和spark开发做准备.让我们键盘作伴开始吧. 安装Ubuntu Server在安装ubuntu之前,需要安装虚拟机软件,本文使用Vmare15, 安装配置自行搞定.  下载Ubuntu server 18.10: 下载地址 安装过程参考官网: 教程  下面说明介个问题:">
<meta name="keywords" content="Big Data">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据之配置本地虚拟机集群">
<meta property="og:url" content="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/index.html">
<meta property="og:site_name" content="ixyxj">
<meta property="og:description" content="概述大数据需要多台服务器集群, 如果用云服务器的话让很多新手都望之却步, 我们来配置穷逼本地虚拟机集群.这也为后面的hadoop和spark开发做准备.让我们键盘作伴开始吧. 安装Ubuntu Server在安装ubuntu之前,需要安装虚拟机软件,本文使用Vmare15, 安装配置自行搞定.  下载Ubuntu server 18.10: 下载地址 安装过程参考官网: 教程  下面说明介个问题:">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/1.png">
<meta property="og:image" content="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/2.png">
<meta property="og:updated_time" content="2019-02-15T10:05:29.146Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大数据之配置本地虚拟机集群">
<meta name="twitter:description" content="概述大数据需要多台服务器集群, 如果用云服务器的话让很多新手都望之却步, 我们来配置穷逼本地虚拟机集群.这也为后面的hadoop和spark开发做准备.让我们键盘作伴开始吧. 安装Ubuntu Server在安装ubuntu之前,需要安装虚拟机软件,本文使用Vmare15, 安装配置自行搞定.  下载Ubuntu server 18.10: 下载地址 安装过程参考官网: 教程  下面说明介个问题:">
<meta name="twitter:image" content="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/">





  <title>大数据之配置本地虚拟机集群 | ixyxj</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?edad59d259128594179f3be5130b43c3";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ixyxj</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">one people and a city</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://ixyxj.github.io/2019/01/08/大数据之配置本地虚拟机集群/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xyxj">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ixyxj">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">大数据之配置本地虚拟机集群</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-08T15:11:25+08:00">
                2019-01-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>大数据需要多台服务器集群, 如果用云服务器的话让很多新手都望之却步, 我们来配置穷逼本地虚拟机集群.这也为后面的hadoop和spark开发做准备.让我们键盘作伴开始吧.</p>
<h3 id="安装Ubuntu-Server"><a href="#安装Ubuntu-Server" class="headerlink" title="安装Ubuntu Server"></a>安装Ubuntu Server</h3><p>在安装ubuntu之前,需要安装虚拟机软件,本文使用Vmare15, 安装配置自行搞定.</p>
<ol>
<li>下载Ubuntu server 18.10: <a href="https://www.ubuntu.com/download/server/thank-you?version=18.10&amp;architecture=amd64" target="_blank" rel="noopener">下载地址</a></li>
<li>安装过程参考官网: <a href="https://tutorials.ubuntu.com/tutorial/tutorial-install-ubuntu-server#0" target="_blank" rel="noopener">教程</a></li>
</ol>
<p>下面说明介个问题:</p>
<ul>
<li>VMare 网络适配器连接方式:<ul>
<li>桥接模式:这个模式就像是虚拟出来的一个独立的主机,可以访问物理网络,但是需要自行配置IP地址, 子网掩码,而且必须和宿主机器处于同一网段.</li>
<li>NAT模式: 这种是应用在Internet网关和路由器上,虚拟出一个网卡,虚拟出来的网卡和虚拟机的IP处于一个地址段.</li>
<li>仅主机模式(host only): 只是让主机和虚拟机之间的网络互动, 虚拟机访问不到Internet.</li>
</ul>
</li>
</ul>
<p>虚拟机安装完毕!!!!</p>
<p>设置网络模式:</p>
<ul>
<li>vmare: 编辑 -&gt; 选择网络选择器 -&gt; 将vmnet1主机模式设置 -&gt; </li>
</ul>
<img src="/2019/01/08/大数据之配置本地虚拟机集群/1.png">
<ul>
<li>设置主机的网络: 打开网络和Internet设置 -&gt; 以太网 -&gt; 更换适配器选项 -&gt; 右键VMnet1属性 -&gt; </li>
</ul>
<img src="/2019/01/08/大数据之配置本地虚拟机集群/2.png">
<p>设置基本原则: 虚拟机采用静态IP,与VMare1处于一个网段内.</p>
<ul>
<li><p>虚拟机选择桥接模式</p>
</li>
<li><p>修改系统参数</p>
<ul>
<li>修改主机名: /etc/hostname</li>
<li>修改系统网络参数: /etc/network/interfaces</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">auto eth0</span><br><span class="line"><span class="meta">#</span>iface eth0 inet dhcp					dhcp的配置</span><br><span class="line">iface eth0 inet static                    # eth0设置为静态IP</span><br><span class="line">address 192.168.1.45</span><br><span class="line">netmast 255.255.255.0</span><br><span class="line">gateway 192.168.1.1</span><br><span class="line">broadcast 192.168.1.255</span><br></pre></td></tr></table></figure>
<p>mac地址配置文件: /etc/udev.rules.d/70-persistent-net.rules 如果克隆虚拟机找不到网卡就rm掉这个文件.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 网络生效</span><br><span class="line">sudo /etc/init.d/networking restart</span><br><span class="line"><span class="meta">#</span> or</span><br><span class="line">sudo ifup eth0</span><br></pre></td></tr></table></figure>
<ul>
<li>修改DNS配置</li>
</ul>
<p>配置: 在/etc/resolvconf/resolv.conf.d/新建一个tail文件写入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nameserver 192.168.1.1</span><br><span class="line">nameserver xx.xx.xx.xx</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="远程控制server"><a href="#远程控制server" class="headerlink" title="远程控制server"></a>远程控制server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br><span class="line">sudo apt install openssh-server				#ubuntu18已经安装好了</span><br><span class="line">sudo apt install openssh-client</span><br></pre></td></tr></table></figure>
<h3 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h3><p>使用没有界面的jdk所用需要使用wget来下载jdk,安装openjdk也是一样;</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 只有这样才能下载成功</span><br><span class="line"><span class="meta">&gt;</span> wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" https://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.tar.gz</span><br><span class="line"><span class="meta">#</span> 解压</span><br><span class="line"><span class="meta">&gt;</span> tar -zxvf jdk-8u191-linux-x64.tar.gz -C /usr/lib/jvm/</span><br><span class="line"><span class="meta">&gt;</span> sudo ln -s jdk1.8.0_191 java</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 下载scala</span><br><span class="line"><span class="meta">&gt;</span> wget --no-check-certificate --no-cookies --header "Cookie: oraclelicense=accept-securebackup-cookie" https://downloads.lightbend.com/scala/2.12.8/scala-2.12.8.tgz</span><br><span class="line"><span class="meta">&gt;</span> tar zxvf scala-2.12.8.tgz -C /usr/lib/jvm/</span><br><span class="line"><span class="meta">&gt;</span> cd /usr/lib/jvm/</span><br><span class="line"><span class="meta">&gt;</span> sudo ln -s scala-2.12.8 scala</span><br></pre></td></tr></table></figure>
<p>测试Scala</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">xyxj@u18_data1:~$ scala</span><br><span class="line">Welcome to Scala 2.12.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191).</span><br><span class="line">Type in expressions for evaluation. Or try :help.</span><br><span class="line"><span class="meta">scala&gt;</span> :help</span><br><span class="line">All commands can be abbreviated, e.g., :he instead of :help.</span><br><span class="line">:completions &lt;string&gt;    output completions for the given string</span><br><span class="line">:edit &lt;id&gt;|&lt;line&gt;        edit history</span><br><span class="line">:help [command]          print this summary or command-specific help</span><br><span class="line">:history [num]           show the history (optional num is commands to show)</span><br><span class="line">:h? &lt;string&gt;             search the history</span><br><span class="line">:imports [name name ...] show import history, identifying sources of names</span><br><span class="line">:implicits [-v]          show the implicits in scope</span><br><span class="line">:javap &lt;path|class&gt;      disassemble a file or class name</span><br><span class="line">:line &lt;id&gt;|&lt;line&gt;        place line(s) at the end of history</span><br><span class="line">:load &lt;path&gt;             interpret lines in a file</span><br><span class="line">:paste [-raw] [path]     enter paste mode or paste a file</span><br><span class="line">:power                   enable power user mode</span><br><span class="line">:quit                    exit the interpreter</span><br><span class="line">:replay [options]        reset the repl and replay all previous commands</span><br><span class="line">:require &lt;path&gt;          add a jar to the classpath</span><br><span class="line">:reset [options]         reset the repl to its initial state, forgetting all session entries</span><br><span class="line">:save &lt;path&gt;             save replayable session to a file</span><br><span class="line">:sh &lt;command line&gt;       run a shell command (result is implicitly =&gt; List[String])</span><br><span class="line">:settings &lt;options&gt;      update compiler options, if possible; see reset</span><br><span class="line">:silent                  disable/enable automatic printing of results</span><br><span class="line">:type [-v] &lt;expr&gt;        display the type of an expression without evaluating it</span><br><span class="line">:kind [-v] &lt;type&gt;        display the kind of a type. see also :help kind</span><br><span class="line">:warnings                show the suppressed warnings from the most recent line which had any</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 退出</span><br><span class="line"><span class="meta">scala&gt;</span> :quit</span><br></pre></td></tr></table></figure>
<p>环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> jdk</span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> scala</span><br><span class="line">export SCALA_HOME=/usr/lib/jvm/scala</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure>
<h3 id="免密钥登录"><a href="#免密钥登录" class="headerlink" title="免密钥登录"></a>免密钥登录</h3><p>需要使用ssh-keygen创建一对公私钥. 由于ubuntu18已经安装ssh,如果没有安装需要安装:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install ssh</span><br><span class="line"><span class="meta">#</span> create</span><br><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p>略…..</p>
<ol>
<li>先将win10免密钥登录主虚拟机</li>
</ol>
<p><strong>将win10上的公钥拷贝到/.ssh/authorized_keys</strong></p>
<ol start="2">
<li>然后将各个界面的公钥相互验证….完毕</li>
</ol>
<h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>官网: <a href="https://archive.apache.org/dist/hadoop/common/" target="_blank" rel="noopener">全部版本下载地址</a></p>
<p>下载2.6.0版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; https://archive.apache.org/dist/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz</span><br><span class="line">$ sudo tar zxvf hadoop-2.6.0.tar.gz -C /usr/local</span><br></pre></td></tr></table></figure>
<p>如果下载的很慢就使用ftp:</p>
<blockquote>
<p>注意ftp连接失败的话, 看看端口号是否21改成22,即使用sftp连接.</p>
</blockquote>
<p>环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br></pre></td></tr></table></figure>
<p><strong>必须配置JAVA_HOME</strong></p>
<ol>
<li>core-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>        </span><br><span class="line">	    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://Master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/home/bigdata/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>131702<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li>yarn-site.xml</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="3">
<li>hdfs-site.xml , 创建namenode和datanode</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /home/hdfs/namenode</span><br><span class="line">sudo mkdir -p /home/hdfs/datanode</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/hdfs/dfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>Master:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>配置slaves 3.0是workers</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x.x.x.x worker1</span><br><span class="line">x.x.x.x worker2</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>格式化namenode</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop namanode -format</span><br></pre></td></tr></table></figure>
<h3 id="Spark安装部署"><a href="#Spark安装部署" class="headerlink" title="Spark安装部署"></a>Spark安装部署</h3><p>官网下载: <a href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener">https://spark.apache.org/downloads.html</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> sudo tar zxvf spark-2.4.0-bin-hadoop2.6.tgz -C /usr/local</span><br><span class="line"><span class="meta">$</span> sudo ln -s spark-2.4.0-bin-hadoop2.6/ spark24</span><br><span class="line"><span class="meta">$</span> cd ~</span><br><span class="line"><span class="meta">$</span> sudo vim .profile</span><br></pre></td></tr></table></figure>
<p>添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> spark</span><br><span class="line">export SPARK_HOME=/usr/local/spark24</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure>
<ol>
<li>打开/etc/hosts</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x.x.x.x Master</span><br><span class="line">x.x.x.x worker1</span><br><span class="line">x.x.x.x worker2</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>配置</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/local/spark24</span><br><span class="line">$ cd conf</span><br><span class="line">$ sudo spark-env.sh</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">xyxj@u18_data1:~$ cd /usr/local/spark24</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24$ ls</span><br><span class="line">bin   data      jars        LICENSE   NOTICE  R          RELEASE  yarn</span><br><span class="line">conf  examples  kubernetes  licenses  python  README.md  sbin</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24$ cd conf</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24/conf$ ls</span><br><span class="line">docker.properties.template   slaves.template</span><br><span class="line">fairscheduler.xml.template   spark-defaults.conf.template</span><br><span class="line">log4j.properties.template    spark-env.sh.template</span><br><span class="line">metrics.properties.template</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24/conf$ sudo cp spark-env.sh.template spark-env.sh</span><br><span class="line">[sudo] password for xyxj: </span><br><span class="line">xyxj@u18_data1:/usr/local/spark24/conf$ ls</span><br><span class="line">docker.properties.template   slaves.template</span><br><span class="line">fairscheduler.xml.template   spark-defaults.conf.template</span><br><span class="line">log4j.properties.template    spark-env.sh</span><br><span class="line">metrics.properties.template  spark-env.sh.template</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24/conf$ sudo vim spark-env.sh</span><br><span class="line">xyxj@u18_data1:/usr/local/spark24/conf$ sudo cp slaves.template slaves</span><br></pre></td></tr></table></figure>
<p>在末尾添加:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> mine settings</span><br><span class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;</span><br><span class="line">export SCALA_HOME=$&#123;SCALA_HOME&#125;</span><br><span class="line">export SPARK_MASTER_IP=192.168.80.128</span><br><span class="line">export SPARK_WORKDER_MEMORY=1g</span><br></pre></td></tr></table></figure>
<p>在slaves后加入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># Licensed to the Apache Software Foundation (ASF) under one or more</span><br><span class="line"># contributor license agreements.  See the NOTICE file distributed with</span><br><span class="line"># this work for additional information regarding copyright ownership.</span><br><span class="line"># The ASF licenses this file to You under the Apache License, Version 2.0</span><br><span class="line"># (the &quot;License&quot;); you may not use this file except in compliance with</span><br><span class="line"># the License.  You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line"># A Spark Worker will be started on each of the machines listed below.</span><br><span class="line">workder1</span><br><span class="line">workder2</span><br></pre></td></tr></table></figure>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format</span><br><span class="line">xyxj@Master /u/l/hadoop-2.6.0&gt; hadoop namenode -format</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">19/01/10 10:04:30 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = Master/0.0.0.0</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 2.6.0</span><br><span class="line">...</span><br><span class="line">19/01/10 10:04:31 INFO util.ExitUtil: Exiting with status 1</span><br><span class="line">19/01/10 10:04:31 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at Master/0.0.0.0</span><br><span class="line">************************************************************/</span><br></pre></td></tr></table></figure>
<p>分别启动<br>sudo start-dfs.sh<br>sudo start-yarn.sh</p>
<h3 id="使用pssh"><a href="#使用pssh" class="headerlink" title="使用pssh"></a>使用pssh</h3><p>安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install pssh</span><br><span class="line"><span class="meta">#</span> centos</span><br><span class="line"><span class="meta">#</span> 安装好 epel 源</span><br><span class="line">yum install -y epel-release</span><br><span class="line"><span class="meta">#</span> 安装 pssh 工具包</span><br><span class="line">yum install -y pssh</span><br></pre></td></tr></table></figure>
<p>设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">echo "alias pssh=parallel-ssh" &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</span><br><span class="line">echo "alias pscp=parallel-scp" &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</span><br><span class="line">echo "alias prsync=parallel-rsync" &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</span><br><span class="line">echo "alias pnuke=parallel-nuke" &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</span><br><span class="line">echo "alias pslurp=parallel-slurp" &gt;&gt; ~/.bashrc &amp;&amp; . ~/.bashrc</span><br><span class="line"></span><br><span class="line">--version：查看版本</span><br><span class="line">--help：查看帮助，即此信息</span><br><span class="line">-h：主机文件列表，内容格式"[user@]host[:port]"</span><br><span class="line">-H：主机字符串，内容格式"[user@]host[:port]"</span><br><span class="line">-l：登录使用的用户名</span><br><span class="line">-p：并发的线程数【可选】</span><br><span class="line">-o：输出的文件目录【可选】</span><br><span class="line">-e：错误输入文件【可选】</span><br><span class="line">-t：TIMEOUT 超时时间设置，0无限制【可选】</span><br><span class="line">-O：SSH的选项</span><br><span class="line">-v：详细模式</span><br><span class="line">-A：手动输入密码模式</span><br><span class="line">-x：额外的命令行参数使用空白符号，引号，反斜线处理</span><br><span class="line">-X：额外的命令行参数，单个参数模式，同-x</span><br><span class="line">-i：每个服务器内部处理信息输出</span><br><span class="line">-P：打印出服务器返回信息</span><br></pre></td></tr></table></figure>
<h3 id="拷贝公钥"><a href="#拷贝公钥" class="headerlink" title="拷贝公钥"></a>拷贝公钥</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">xyxj@Master:~$ ps aux | grep ssh</span><br><span class="line">root        881  0.0  0.3  31528  6336 ?        Ss   02:41   0:00 /usr/sbin/sshd -D</span><br><span class="line">root       5183  0.0  0.3  63244  7156 ?        Ss   08:48   0:00 sshd: xyxj [priv]</span><br><span class="line">xyxj       5303  0.0  0.2  63244  4488 ?        S    08:48   0:00 sshd: xyxj@notty</span><br><span class="line">xyxj       5306  0.0  0.0   2628  1720 ?        Ss   08:48   0:00 /usr/lib/openssh/sftp-server</span><br><span class="line">root       6795  0.0  0.3  62968  6936 ?        Ss   09:46   0:00 sshd: xyxj [priv]</span><br><span class="line">xyxj       6893  0.0  0.2  63244  4996 ?        S    09:46   0:00 sshd: xyxj@pts/1</span><br><span class="line">root       7275  0.0  0.3  62968  7128 ?        Ss   09:59   0:00 sshd: xyxj [priv]</span><br><span class="line">xyxj       7374  0.0  0.2  63244  4780 ?        S    09:59   0:00 sshd: xyxj@pts/0</span><br><span class="line">xyxj       8284  0.0  0.2  15312  5548 pts/1    T    10:09   0:00 ssh Master cd /usr/local/hadoop-2.6.0 ; /usr/local/hadoop-2.6.0/sbin/hadoop-daemon.sh --config /usr/local/hadoop-2.6.0/etc/hadoop --script /usr/local/hadoop/sbin/hdfs start secondarynamenode</span><br><span class="line">xyxj       9553  0.0  0.0   6256   824 pts/0    S+   10:54   0:00 grep --color=auto ssh</span><br><span class="line"><span class="meta">#</span>创建密钥</span><br><span class="line">xyxj@Master:~$ ssh-keygen </span><br><span class="line"><span class="meta">#</span>拷贝公钥</span><br><span class="line">xyxj@Master:~$ ssh-copy-id -i .ssh/id_rsa.pub -p 22 root@192.168.80.131</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: ".ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host '192.168.80.131 (192.168.80.131)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:PNQmA4f5ihVYBSlRRsD9ethRmG6R5o3rz/ynQTcPJlM.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">xyxj@192.168.80.131's password: </span><br><span class="line">Permission denied, please try again.</span><br><span class="line">xyxj@192.168.80.131's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh -p '22' 'xyxj@192.168.80.131'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br></pre></td></tr></table></figure>
<p>这是在worker1客机就生成了 authorized_keys</p>
<p><strong>允许root ssh登录</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ssh/sshd_config #将PermitRootLogin yes</span><br><span class="line">sudo /etc/init.d/ssh restart</span><br></pre></td></tr></table></figure>
<h3 id="向集群拷贝环境"><a href="#向集群拷贝环境" class="headerlink" title="向集群拷贝环境"></a>向集群拷贝环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/lib/jvm /usr/lib/</span><br><span class="line">[1] 17:02:00 [SUCCESS] root@192.168.80.132</span><br><span class="line">[2] 17:02:00 [SUCCESS] root@192.168.80.131</span><br><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/local/hadoop /usr/local/</span><br><span class="line">[1] 17:04:52 [SUCCESS] root@192.168.80.132</span><br><span class="line">[2] 17:04:52 [SUCCESS] root@192.168.80.131</span><br><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/local/spark24 /usr/local/</span><br><span class="line">[1] 17:05:49 [SUCCESS] root@192.168.80.132</span><br><span class="line">[2] 17:05:49 [SUCCESS] root@192.168.80.131</span><br><span class="line">root@Master:~# pscp -h hosts.txt /etc/hosts /etc/</span><br><span class="line">[1] 17:08:32 [SUCCESS] root@192.168.80.131</span><br><span class="line">[2] 17:08:32 [SUCCESS] root@192.168.80.132</span><br><span class="line">root@Master:~# pscp -h hosts.txt /root/.profile /root</span><br><span class="line">[1] 17:09:30 [SUCCESS] root@192.168.80.132</span><br><span class="line">[2] 17:09:30 [SUCCESS] root@192.168.80.131</span><br></pre></td></tr></table></figure>
<p>有个问题: 在启动的时候hadoop和spark都是带上版本号的,所以上面要重新传一下或者改成hadoop-2.6.0等</p>
<p>然后进行链接:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/local/hadoop-2.6.0 /usr/local/</span><br><span class="line">[1] 17:22:04 [SUCCESS] root@192.168.80.132</span><br><span class="line">[2] 17:22:05 [SUCCESS] root@192.168.80.131</span><br><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/local/spark /usr/local/</span><br><span class="line">spark24/                   spark-2.4.0-bin-hadoop2.6/ </span><br><span class="line">root@Master:~# pscp -h hosts.txt -r /usr/local/spark-2.4.0-bin-hadoop2.6/ /usr/local/</span><br><span class="line">[1] 17:23:49 [SUCCESS] root@192.168.80.131</span><br><span class="line">[2] 17:23:49 [SUCCESS] root@192.168.80.132</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 链接</span><br><span class="line"><span class="meta">&gt;</span> ln -s hadoop-2.6.0 hadoop | ln -s spark-2.4.0-bin-hadoop2.6/ spark24</span><br></pre></td></tr></table></figure>
<p>启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/hadoop/bin/hadoop namenode -format</span><br><span class="line">/usr/local/hadoop/sbin/start-dfs.sh</span><br><span class="line">/usr/local/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>hadoop启动成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">root@Master:~# /usr/local/hadoop/sbin/start-dfs.sh</span><br><span class="line">Starting namenodes on [Master]</span><br><span class="line">root@master's password: </span><br><span class="line">Master: starting namenode, logging to /usr/local/hadoop-2.6.0/logs/hadoop-root-namenode-Master.out</span><br><span class="line">192.168.80.132: datanode running as process 2456. Stop it first.</span><br><span class="line">worker2: datanode running as process 2456. Stop it first.</span><br><span class="line">192.168.80.131: datanode running as process 1953. Stop it first.</span><br><span class="line">worker1: datanode running as process 1953. Stop it first.</span><br><span class="line">Starting secondary namenodes [Master]</span><br><span class="line">root@master's password: </span><br><span class="line">Master: secondarynamenode running as process 2895. Stop it first.</span><br><span class="line"></span><br><span class="line">root@Master:~# /usr/local/hadoop/sbin/start-yarn.sh </span><br><span class="line">starting yarn daemons</span><br><span class="line">resourcemanager running as process 4634. Stop it first.</span><br><span class="line">192.168.80.132: nodemanager running as process 3411. Stop it first.</span><br><span class="line">worker2: nodemanager running as process 3411. Stop it first.</span><br><span class="line">worker1: nodemanager running as process 2888. Stop it first.</span><br><span class="line">192.168.80.131: nodemanager running as process 2888. Stop it first.</span><br></pre></td></tr></table></figure>
<p>spark</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@Master:~# /usr/local/spark24/sbin/start-all.sh</span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /usr/local/spark24/logs/spark-root-org.apache.spark.deploy.master.Master-1-Master.out</span><br><span class="line">workder2: Warning: Permanently added 'workder2' (ECDSA) to the list of known hosts.</span><br><span class="line">root@workder2's password: </span><br><span class="line">workder2: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/spark24/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-Master.out</span><br><span class="line">workder1: ssh: Could not resolve hostname workder1: Temporary failure in name resolution</span><br></pre></td></tr></table></figure>
<p>在master上执行jps</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@Master:~# jps</span><br><span class="line">9127 NameNode</span><br><span class="line">9704 Worker</span><br><span class="line">4634 ResourceManager</span><br><span class="line">9403 SecondaryNameNode</span><br><span class="line">9756 Jps</span><br><span class="line">9534 Master</span><br></pre></td></tr></table></figure>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><blockquote>
<p>workder1: Warning: Permanently added ‘workder1’ (ECDSA) to the list of known hosts.</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/ssh/ssh_config</span><br><span class="line"><span class="meta">#</span>StrictHostKeyChecking ask去掉注释</span><br><span class="line">StrictHostKeyChecking no</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="xyxj 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="xyxj 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Big-Data/" rel="tag"># Big Data</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/07/大数据入门概述/" rel="next" title="大数据入门概述">
                <i class="fa fa-chevron-left"></i> 大数据入门概述
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/09/Linux基础/" rel="prev" title="Linux基础">
                Linux基础 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="xyxj">
            
              <p class="site-author-name" itemprop="name">xyxj</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">22</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/ixyxj" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xyxjun@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Ubuntu-Server"><span class="nav-number">2.</span> <span class="nav-text">安装Ubuntu Server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#远程控制server"><span class="nav-number">3.</span> <span class="nav-text">远程控制server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装JDK"><span class="nav-number">4.</span> <span class="nav-text">安装JDK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#免密钥登录"><span class="nav-number">5.</span> <span class="nav-text">免密钥登录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Hadoop"><span class="nav-number">6.</span> <span class="nav-text">安装Hadoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark安装部署"><span class="nav-number">7.</span> <span class="nav-text">Spark安装部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动"><span class="nav-number">8.</span> <span class="nav-text">启动</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用pssh"><span class="nav-number">9.</span> <span class="nav-text">使用pssh</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#拷贝公钥"><span class="nav-number">10.</span> <span class="nav-text">拷贝公钥</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#向集群拷贝环境"><span class="nav-number">11.</span> <span class="nav-text">向集群拷贝环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题"><span class="nav-number">12.</span> <span class="nav-text">问题</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ixyxj</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count"></span>
  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
